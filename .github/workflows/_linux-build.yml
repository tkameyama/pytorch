name: linux-build

on:
  workflow_call:
    inputs:
      build-environment:
        required: true
        type: string
      docker-image-name:
        required: true
        type: string
      build-generates-artifacts:
        required: false
        type: boolean
        default: true
      build-with-debug:
        required: false
        type: boolean
        default: false
    outputs:
      docker-image:
        value: ${{ jobs.build.outputs.docker-image }}

env:
  IN_CI: 1 # TODO delete in favor of GITHUB_ACTIONS
  IS_GHA: 1 # TODO delete in favor of GITHUB_ACTIONS

jobs:
  build:
    runs-on: [self-hosted, linux.2xlarge]
    timeout-minutes: 240
    outputs:
      docker-image: ${{ steps.calculate-docker-image.outputs.docker-image }}
    steps:
      - name: Clean workspace
        shell: bash
        run: |
          echo "${GITHUB_WORKSPACE}"
          sudo rm -rf "${GITHUB_WORKSPACE}"
          mkdir "${GITHUB_WORKSPACE}"

      - name: Checkout PyTorch
        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9
        with:
          ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}
          # deep clone, to allow use of git merge-base
          fetch-depth: 0
          submodules: recursive

      - name: Setup Linux
        uses: ./.github/actions/setup-linux
        with:
          github-secret: ${{ secrets.GITHUB_TOKEN }}

      - name: Calculate docker image
        id: calculate-docker-image
        uses: ./.github/actions/calculate-docker-image
        with:
          docker-image-name: ${{ inputs.docker-image-name }}
          xla: ${{ contains(inputs.build-environment, 'xla') }}

      - name: Pull Docker image
        run: |
          retry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }
          retry docker pull ${{ steps.calculate-docker-image.outputs.docker-image }}

      - name: Parse ref
        id: parse-ref
        run: .github/scripts/parse_ref.py

      - name: Build
        env:
          BUILD_ENVIRONMENT: ${{ inputs.build-environment }}
          BRANCH: ${{ steps.parse-ref.outputs.branch }}
          JOB_BASE_NAME: ${{ inputs.build-environment }}-build
          # TODO duplicated
          AWS_DEFAULT_REGION: us-east-1
          PR_NUMBER: ${{ github.event.pull_request.number }}
          SHA1: ${{ github.event.pull_request.head.sha || github.sha }}
          SCCACHE_BUCKET: ossci-compiler-cache-circleci-v2
          XLA_CLANG_CACHE_S3_BUCKET_NAME: ossci-compiler-clang-cache-circleci-xla
          CUSTOM_TEST_ARTIFACT_BUILD_DIR: build/custom_test_artifacts
          PR_LABELS: ${{ toJson(github.event.pull_request.labels.*.name) }}
          TORCH_CUDA_ARCH_LIST: 5.2
          DOCKER_IMAGE: ${{ steps.calculate-docker-image.outputs.docker-image }}
          DEBUG: ${{ inputs.build-with-debug && '1' || '0' }}
        run: |
          # detached container should get cleaned up by teardown_ec2_linux
          container_name=$(docker run \
            -e BUILD_ENVIRONMENT \
            -e JOB_BASE_NAME \
            -e MAX_JOBS="$(nproc --ignore=2)" \
            -e AWS_DEFAULT_REGION \
            -e IS_GHA \
            -e PR_NUMBER \
            -e SHA1 \
            -e BRANCH \
            -e GITHUB_RUN_ID \
            -e SCCACHE_BUCKET \
            ${{ contains(inputs.build-environment, 'xla') && '-e XLA_CUDA=0' || '' }} \
            -e XLA_CLANG_CACHE_S3_BUCKET_NAME \
            -e CUSTOM_TEST_ARTIFACT_BUILD_DIR \
            -e SKIP_SCCACHE_INITIALIZATION=1 \
            -e TORCH_CUDA_ARCH_LIST \
            -e PR_LABELS \
            --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
            --security-opt seccomp=unconfined \
            --cap-add=SYS_PTRACE \
            --tty \
            --detach \
            --user jenkins \
            -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
            -w /var/lib/jenkins/workspace \
            "${DOCKER_IMAGE}"
          )
          docker exec -t "${container_name}" sh -c 'sudo chown -R jenkins . && .jenkins/pytorch/build.sh'

      - name: Display and upload binary build size statistics (Click Me)
        # temporary hack: set CIRCLE_* vars, until we update
        # tools/stats/print_test_stats.py to natively support GitHub Actions
        env:
          SCRIBE_GRAPHQL_ACCESS_TOKEN: ${{ secrets.SCRIBE_GRAPHQL_ACCESS_TOKEN }}
          BRANCH: ${{ steps.parse-ref.outputs.branch }}
          TAG: ${{ steps.parse-ref.outputs.tag }}
          WORKFLOW_ID: ${{ github.run_id }}
        run: |
          COMMIT_TIME=$(git log --max-count=1 --format=%ct || echo 0)
          export COMMIT_TIME
          pip3 install requests==2.26 boto3==1.16.34
          python3 -m tools.stats.upload_binary_size_to_scuba || exit 0

      - name: Chown workspace
        if: always()
        env:
          # TODO duplicated
          ALPINE_IMAGE: "308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine"
        run: |
          # Ensure the working directory gets chowned back to the current user
          docker run --rm -v "$(pwd)":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .

      - name: Archive artifacts into zip
        if: inputs.build-generates-artifacts
        run: |
          zip -1 -r artifacts.zip dist/ build/custom_test_artifacts build/lib build/bin .pytorch-test-times.json

      - name: Store PyTorch Build Artifacts on S3
        uses: seemethere/upload-artifact-s3@v3
        if: inputs.build-generates-artifacts
        with:
          name: ${{ inputs.build-environment }}
          retention-days: 14
          if-no-files-found: error
          path: artifacts.zip

      - name: Hold runner for 2 hours or until ssh sessions have drained
        # TODO working-directory: !{{ pytorch_directory }}
        # Always hold for active ssh sessions
        if: always()
        run: .github/scripts/wait_for_ssh_to_drain.sh

      - name: Kill containers, clean up images
        if: always()
        run: |
          # ignore expansion of "docker ps -q" since it could be empty
          # shellcheck disable=SC2046
          docker stop $(docker ps -q) || true
          # Prune all of the docker images
          docker system prune -af
