name: trunk

on:
  push:
    branches:
      - master
      - main
      - release/*
    tags:
      - ciflow/trunk/*

concurrency:
  group: trunk-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  parallelnative-linux-xenial-py3_7-gcc5_4-build:
    name: parallelnative-linux-xenial-py3.7-gcc5.4
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: parallelnative-linux-xenial-py3.7-gcc5.4
      docker-image-name: pytorch-linux-xenial-py3.7-gcc5.4

  parallelnative-linux-xenial-py3_7-gcc5_4-test:
    name: parallelnative-linux-xenial-py3.7-gcc5.4
    uses: ./.github/workflows/_linux-test.yml
    needs: parallelnative-linux-xenial-py3_7-gcc5_4-build
    with:
      build-environment: parallelnative-linux-xenial-py3.7-gcc5.4
      docker-image: ${{ needs.parallelnative-linux-xenial-py3_7-gcc5_4-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 2, runner: "linux.2xlarge" },
          { config: "default", shard: 2, num_shards: 2, runner: "linux.2xlarge" },
        ]}

  # Build PyTorch with BUILD_CAFFE2=ON
  caffe2-linux-xenial-py3_7-gcc5_4-build:
    name: caffe2-linux-xenial-py3.7-gcc5.4
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: caffe2-linux-xenial-py3.7-gcc5.4
      docker-image-name: pytorch-linux-xenial-py3.7-gcc5.4

  linux-bionic-cuda10_2-py3_9-gcc7-build:
    name: linux-bionic-cuda10.2-py3.9-gcc7
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-bionic-cuda10.2-py3.9-gcc7
      docker-image-name: pytorch-linux-bionic-cuda10.2-cudnn7-py3.9-gcc7

  linux-bionic-cuda10_2-py3_9-gcc7-test:
    name: linux-bionic-cuda10.2-py3.9-gcc7
    uses: ./.github/workflows/_linux-test.yml
    needs: linux-bionic-cuda10_2-py3_9-gcc7-build
    with:
      build-environment: linux-bionic-cuda10.2-py3.9-gcc7
      docker-image: ${{ needs.linux-bionic-cuda10_2-py3_9-gcc7-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "nogpu_NO_AVX", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "nogpu_NO_AVX2", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "jit_legacy", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "distributed", shard: 1, num_shards: 1, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "multigpu", shard: 1, num_shards: 1, runner: "linux.16xlarge.nvidia.gpu" },
        ]}

  libtorch-linux-xenial-cuda10_2-py3_7-gcc7-build:
    name: libtorch-linux-xenial-cuda10.2-py3.7-gcc7
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: libtorch-linux-xenial-cuda10.2-py3.7-gcc7
      docker-image-name: pytorch-linux-xenial-cuda10.2-cudnn7-py3-gcc7
      build-generates-artifacts: false

  libtorch-linux-xenial-cuda11_3-py3_7-gcc7-build:
    name: libtorch-linux-xenial-cuda11.3-py3.7-gcc7
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: libtorch-linux-xenial-cuda11.3-py3.7-gcc7
      docker-image-name: pytorch-linux-xenial-cuda11.3-cudnn8-py3-gcc7
      build-generates-artifacts: false

  # no-ops builds test USE_PER_OPERATOR_HEADERS=0 where ATen/ops is not generated
  linux-xenial-cuda11_3-py3_7-gcc7-no-ops-build:
    name: linux-xenial-cuda11.3-py3.7-gcc7-no-ops
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-xenial-cuda11.3-py3.7-gcc7-no-ops
      docker-image-name: pytorch-linux-xenial-cuda11.3-cudnn8-py3-gcc7

  linux-bionic-rocm4_5-py3_7-distributed-build:
    name: linux-bionic-rocm4.5-py3.7-distributed
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-bionic-rocm4.5-py3.7
      docker-image-name: pytorch-linux-bionic-rocm4.5-py3.7

  linux-bionic-rocm4_5-py3_7-distributed-test:
    name: linux-bionic-rocm4.5-py3.7-distributed
    uses: ./.github/workflows/_rocm-test.yml
    needs: linux-bionic-rocm4_5-py3_7-distributed-build
    with:
      build-environment: linux-bionic-rocm4.5-py3.7
      docker-image: ${{ needs.linux-bionic-rocm4_5-py3_7-distributed-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "distributed", shard: 1, num_shards: 1, runner: "linux.rocm.gpu" },
        ]}
